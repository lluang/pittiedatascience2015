Review of topics in Data Science
========================================================
author: IE 2064 Data Science
date: April 2014

Data science course
===================
type: section


What is data science?
=====================

- *Data Science refers to an emerging area of work concerned with the collection, preparation, analysis, visualization, management, and preservation of large collections of information.* - Jeffrey Stanton

- *The Analytics Section of INFORMS is focused on promoting the use of data-driven analytics and fact-based decision making in practice. The Section recognizes that analytics is seen as both (i) a complete business problem solving and decision making process, and (ii) a broad set of analytical methodologies that enable the creation of business value.*  -  INFORMS Section on Analytics

Machine Learning
================
![Branches of Machine Learning](resources/ml_map.png)

What is Big Data?
=================

-  A recognition that the standard methods and techniques as taught in traditional statistics is inappropriate when data is collected on an automated basis.
-  Traditional statistics research was done on the basis of data scarcity, where data collection was expensive.
-  Design of experiments planned the data collection with the goal of answering a specific question.
-  When data collection became automated, we now had data collection that was not planned for the experiment in question.

Qualities of big data
=====================
left:40%

- Volume
- Velocity
- Variety

***

![3Vs of Big data](resources/BigData3vs.png)

What does a data scientist do?
=========================
type: section

The Data Science Venn Diagram
=============================
left:40%
The primary colors of data
  - Hacking skills,
  - Math and statistics knowledge, and
  - Substantive expertise.

***

![Drew Conway Data Science](resources/Data_Science_VD.png)


Three categories of data science
=======================================

- Descriptive analytics
    - Prepares and analyzes historical data
    - Identifies patterns from samples for reporting of trends
- Predictive analytics
    - Predicts future probabilities and trends
    - Finds relationships in data that may not be readily apparent with descriptive analysis
- Prescriptive analytics
    - Evaluates and determines new ways to operate
    - Targets business objectives
    - Balances all constraints

Data science requirements
========================================================

1. Read in data
2. Handle data of indefinite size
3. Manipulate data
4. Understand the data and problem
5. Mathematical/statistical analysis
6. Presentation of results


Data science applications
==============================
type: section

Application categories
==========================

- Exploratory data analysis
- Text processing
- Predictions

Exploratory data analysis
==========================

-  Visualization
-  Visual cues -  position, size, direction, colors
-  Categories, time series, spatial data
-  Multi-variate visualization
-  Distributions
-  Comparisons

Text processing
=================

-  Frequent word analysis
-  Visualization with word clouds/wordles
-  Text mining
  -  text classification
  -  Clustering
  -  Document summary
  -  Corpus analysis

Predictions
==============

-  The purpose of data mining is we want to make decisions?
-  Given a new observation, how should we react?
-  How do we use our past observations to inform our reaction to a new observation.

Machine learning
====================
type:section

> The purpose of computing is insight, not numbers.
>       - Richard Hamming

Machine Learning
================
left:40%

-  Regression
-  Classification
-  Clustering
-  Dimensionality reduction (feature selection)
-  Model evaluation

***

![Branches of Machine Learning](resources/ml_map.png)


Regression
===========

-  Use training data to develop regression model.
-  Use regression model on test data to generated predicted output scores.

Regression methods
=============

-  Linear regression
-  Recursive partitioning (Classification and regression trees)
-  Support vector machines
-  Goal is to make predictions, not determine if model terms are statically significant

Classification
================

-  From training data, classifications are based on output data.
-  Test data assigned to classes based on predictors.
-  Predictions based on class assigned

Classification methods
===================

-  Recursive partitioning
-  Support Vector machines
-  *k*-Nearest Neighbors
-  Naive Bayes
-  Random Forests

Clustering
==========

-  Look at training data, then generate clusters.
-  Assign test data to clusters.
-  Predictions based on what cluster test data is assigned.


Clustering Methods
==================

-  Modified box-plot rules
-  *k*-Means
-  Outlier based methods
-  Hierarchical clustering

Dimensionality reduction
=========================

-  Classification where there are a large number of features
-  Use methods to reduce the number of potential predictors to a manageable number.

Dimensionality reduction
============================

-  Analysis of Variance (ANOVA)
-  Clustering with factors
-  Random Forests
-  Principle Component Analysis



Choosing between models
==================

-  General principles
-  Comparing predictors
-  Comparing classifications


General principles
=====================

1. Flexibility of models.
2. Models that lead to easy interpretation.
3. Simplicity

Flexibility
===========

-  Some models are very flexible
-  e.g. Boosting, Support Vector Machines
-  Likely to be very accurate emperically
-  Con: very difficult to interpret and gain understanding from the results

Interpretation
=============

-  Some model types lend themselves to easy interpretation
-  e.g. regression methods, naive Bayes, association rules
-  May be less accurate emperically, but leads to understanding about the system
-  Very useful if the goal is to inform a person making the decision as opposed to pure machine learning.

Simplicity
============

-  Use the simplest model that is a reasonable approximation of the complex model
   -  Note: a more complex model should be more accurate, but it may not be more accurate by much.
   -  Tradeoff simplicity for accuracy. If the simpler model is within some measure of error of the more complex one, use the simpler model since there is no significant improvement.


Considerations for predictive models
=============

-  Balance between accuracy and overfitting
  -  The goal of the model is to describe the system, not fit the available data.
-  Balance between identifying all members of a target class and overfitting the dataset you happen to have.

Model evaluation
================================

-  Regression
-  Classification

Regression methods
===============

-  Mean Squared Error based methods
-  Distance methods

Classification methods
==================

-  Receiver operating characteristics
-  Sensitivity vs Specificity
-  Precision vs Recall
-  Lift


Cross-validation
============

  1.  Obtain *k* equally sized and random subsets of the training data.
  2.  For each of these *k* subsets, build a model using the remaining *kâˆ’1* sets.
  3.  Evaluate this model on the *k*th subset.
  4.  After determining the best model, refit the model using all available data. Apply to new observations for predictive modeling.

Results of cross-validation
================================

-  For each candidate model (subset size), cross validation will generate a series of estimates of error.
-  This gives the *estimated prediction error* and standard error bands
-  Identify the best model.
-  Take the sum of the mean error plus the standard error (standard deviation of error).
-  Find the model with lowest level of complexity that is less than this sum. This model balances precision and simplicity.

Measures of complixity
==============

-  Measures of complexity differ depending on the model type.
- Regression - Number of parameters/subset size.
- Tree based models - *cp* complexity parameter
- *kNN* - Number of neighbors
- PCA - Number of principle components
- Lasso - Shrinkage factor
- Partial Least Squares - Number of directions

Regression methods
===============================

-  We can use statistical methods like Mean Squared Error based methods when the prediction is a value that can be compared to the actual value.
-  Similar to methods used in developing regression models (Least Squared Error)

Model criteria
==============

-  Mean absolute error (MAE) between predictions and real values of the target variables.
-  Mean squared error (MSE)
-  Normalized mean squared error (NMSE)

Distance based metrics
=============

-  Create a metric that looks at the distance between the prediction and actual.
-  Note: this is context dependent!
-  Need to define a distance metric. (e.g. square root of some of squares)
-  Need to control for the variation that is in the data.
-  Normalization controls for the variation by dividing the distance by a measure of variation.
