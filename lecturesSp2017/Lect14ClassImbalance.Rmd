---
title: "Class Imbalance"
author: "IE2064 Data Science"
date: "March 2017"
output:
  slidy_presentation: default
---

```{r}
library(DMwR, warn.conflicts = FALSE)
```
Clustering - Supervised approaches
=======================================

-  Clustering based on using labeled data.

Class imbalance problem
========================

-  One problem in classification is that fraudulent reports are a clear minority.
  -  8.1% of inspected reports.
  -  Deciding all reports are valid gives 91% accuracy!
  -  The minority class may be disregarded.
  -  But this is the group we are most interested in!
  
Techniques for working with class imbalance
===========================================

1.  Method that bias the learning process by using evaluation metrics that are more sensitive to minority class examples.
2.  Sampling methods that manipulate the training data to change the class distribution.

Sampling methods that manipulate training data
==============================================

-  *Under-sampling*:  select a small part of the majority class examples to add to the minority class cases.
-  *Over-sampling*: use some process to replicate the minority class examples.

Synthetic Minority Oversampling Technique (SMOTE)
=====================================================

-  Artificially generates new examples of the minority class using the nearest neighbors of these cases. 
-  Undersample majority class so that the dataset is more balanced.

SMOTE with iris data
====================

```{r}
data(iris)
data <- iris[,c(1,2,5)]
data$Species <- factor(ifelse(data$Species == 'setosa','rare','common'))
newData <- SMOTE(Species ~ .,data,perc.over=600)
```
-  Create six new cases for every member of the minority class.
-  Done through random interpolation between the case and its nearest neighbors.
  1.  Identify an observation in the training set of the minority class.
  2.  Identify the $n=5$ nearest neighbors.
  3.  Create a new observation based on randomly drawing predictor values from the $n+1=6$ observations.

SMOTE creates new cases
=======================
```{r}
table(data$Species)
table(newData$Species)
```

-  Use this training data for supervised learning techniques.

Visualizing SMOTE
=================
```{r, echo=FALSE}
par(mfrow=c(1,2))
plot(data[,1],data[,2],pch=19+as.integer(data[,3]),main='Original Data')
plot(newData[,1],newData[,2],pch=19+as.integer(newData[,3]),main="SMOTE'd Data")
```


Data preparation for Naive Bayes
========


```{r, echo=FALSE}
data(sales)
totS <- table(sales$ID)
totP <- table(sales$Prod)
```

```{r, echo=FALSE}
sales$Uprice <- sales$Val/sales$Quant
```

```{r, echo=FALSE}
totS <- table(sales$ID)
totP <- table(sales$Prod)
```

```{r, echo=FALSE}
sales1 <- sales[-which(is.na(sales$Quant) & is.na(sales$Val)),]
sales2 <- sales1[!sales1$Prod %in% c('p2442','p2443'),]
sales2$Prod <- factor(sales2$Prod)
```


```{r, echo=FALSE}
tPrice <- tapply(sales2[sales2$Insp != 'fraud','Uprice'],list(sales2[sales2$Insp != 'fraud','Prod']),median,na.rm=T)
```

```{r, echo=FALSE}
noQuant <- which(is.na(sales2$Quant))
sales2[noQuant,'Quant'] <- ceiling(sales2[noQuant,'Val'] /
                       tPrice[sales2[noQuant,'Prod']])
noVal <- which(is.na(sales2$Val))
sales2[noVal,'Val'] <- sales2[noVal,'Quant'] *
                   tPrice[sales2[noVal,'Prod']]
sales2$Uprice <- sales2$Val/sales2$Quant
```

```{r, echo=FALSE}
avgNDTP <- function(toInsp,train,stats) {
  if (missing(train) && missing(stats)) 
    stop('Provide either the training data or the product stats')
  if (missing(stats)) {
    notF <- which(train$Insp != 'fraud')
    stats <- tapply(train$Uprice[notF],
                    list(Prod=train$Prod[notF]),
                    function(x) {
                      bp <- boxplot.stats(x)$stats
                      c(median=bp[3],iqr=bp[4]-bp[2])
                    })
    stats <- matrix(unlist(stats),
                    length(stats),2,byrow=T,
                    dimnames=list(names(stats),c('median','iqr')))
    stats[which(stats[,'iqr']==0),'iqr'] <- 
        stats[which(stats[,'iqr']==0),'median']
  }

  mdtp <- mean(abs(toInsp$Uprice-stats[toInsp$Prod,'median']) /
               stats[toInsp$Prod,'iqr'])
  return(mdtp)
}
evalOutlierRanking <- function(testSet,rankOrder,Threshold,statsProds) {
  ordTS <- testSet[rankOrder,]
  N <- nrow(testSet)
  nF <- if (Threshold < 1) as.integer(Threshold*N) else Threshold
  cm <- table(c(rep('fraud',nF),rep('ok',N-nF)),ordTS$Insp)
  prec <- cm['fraud','fraud']/sum(cm['fraud',])
  rec <- cm['fraud','fraud']/sum(cm[,'fraud'])
  AVGndtp <- avgNDTP(ordTS[nF,],stats=statsProds)
  return(c(Precision=prec,Recall=rec,avgNDTP=AVGndtp))
}

BPrule <- function(train,test) {
  notF <- which(train$Insp != 'fraud')
  ms <- tapply(train$Uprice[notF],list(Prod=train$Prod[notF]),
               function(x) {
                 bp <- boxplot.stats(x)$stats
                 c(median=bp[3],iqr=bp[4]-bp[2])
               })
  ms <- matrix(unlist(ms),length(ms),2,byrow=T,
               dimnames=list(names(ms),c('median','iqr')))
  ms[which(ms[,'iqr']==0),'iqr'] <- ms[which(ms[,'iqr']==0),'median']
  ORscore <- abs(test$Uprice-ms[test$Prod,'median']) /
             ms[test$Prod,'iqr']
  return(list(rankOrder=order(ORscore,decreasing=T),
              rankScore=ORscore))
}


notF <- which(sales$Insp != 'fraud')
globalStats <- tapply(sales$Uprice[notF],
                      list(Prod=sales$Prod[notF]),
                      function(x) {
                        bp <- boxplot.stats(x)$stats
                        c(median=bp[3],iqr=bp[4]-bp[2])
                      })
globalStats <- matrix(unlist(globalStats),
                length(globalStats),2,byrow=T,
                dimnames=list(names(globalStats),c('median','iqr')))
globalStats[which(globalStats[,'iqr']==0),'iqr'] <- 
   globalStats[which(globalStats[,'iqr']==0),'median']
```

Naive Bayes
============

- *Naive Bayes* is a probabilistic classifier based on Bayes theorem.
-  Assumes independence between predictors, hence *naive*
-  Still fairly successful.
$$P(c|X_1, \ldots, X_p) = \frac{P(c)P(P(X_1, \ldots, X_p|c)}{P(X_1, \ldots, X_p)}$$

Implementation of Naive Bayes
=============================

-  Assume independence to simplify the numerator
$$P(c|X_1, \ldots, X_p) = \frac{P(c)\Pi_{i=1}^p P(X_i|c)}{P(X_1, \ldots, X_p)}$$
-  Estimate probabilities using the labeled test data.

R Implementations
===================

-  Naive Bayes is implemented in many packages.
-  Requires you specify the:
  -  Model
  -  Training data
  -  Predictors
-  Evaluation
  -  Based on hold-out routines

Using Naive Bayes
=================
```{r}
nb <- function(train,test) {
  require(e1071,quietly=T)
  sup <- which(train$Insp != 'unkn')
  data <- train[sup,c('ID','Prod','Uprice','Insp')]
  data$Insp <- factor(data$Insp,levels=c('ok','fraud'))
  model <- naiveBayes(Insp ~ .,data)
  preds <- predict(model,test[,c('ID','Prod','Uprice','Insp')],type='raw')
  return(list(rankOrder=order(preds[,'fraud'],decreasing=T),
              rankScore=preds[,'fraud'])
         )
}
```

Evaluation of Naive Bayes
==========================
```{r}
ho.nb <- function(form, train, test, ...) {
  res <- nb(train,test)
  structure(evalOutlierRanking(test,res$rankOrder,...),
            itInfo=list(preds=res$rankScore,
                        trues=ifelse(test$Insp=='fraud',1,0)
                       )
           )
}
```
```{r, echo=FALSE}
nb.res <- holdOut(learner('ho.nb',
                          pars=list(Threshold=0.1,
                                    statsProds=globalStats)),
                  dataset(Insp ~ .,sales),
                  hldSettings(3,0.3,1234,T),
                  itsInfo=TRUE
                  )
```

Results
========


```{r}
summary(nb.res)
```


```{r, echo=FALSE}
ho.ORh <- function(form, train, test, ...) {
  #require(dprep,quietly=T)
  ntr <- nrow(train)
  all <- rbind(train,test)
  N <- nrow(all)
  ups <- split(all$Uprice,all$Prod)
  r <- list(length=ups)
  for(u in seq(along=ups)) 
    r[[u]] <- if (NROW(ups[[u]]) > 3) 
                 outliers.ranking(ups[[u]])$prob.outliers 
              else if (NROW(ups[[u]])) rep(0,NROW(ups[[u]])) 
              else NULL
  all$lof <- vector(length=N)
  split(all$lof,all$Prod) <- r
  all$lof[which(!(is.infinite(all$lof) | is.nan(all$lof)))] <- 
    SoftMax(all$lof[which(!(is.infinite(all$lof) | is.nan(all$lof)))])
  structure(evalOutlierRanking(test,order(all[(ntr+1):N,'lof'],
                                           decreasing=T),...),
            itInfo=list(preds=all[(ntr+1):N,'lof'],
                        trues=ifelse(test$Insp=='fraud',1,0))
           )
}


orh.res <- holdOut(learner('ho.ORh',
                          pars=list(Threshold=0.1,
                                    statsProds=globalStats)),
                  dataset(Insp ~ .,sales),
                  hldSettings(3,0.3,1234,T),
                  itsInfo=TRUE
                  )
info <- attr(orh.res,'itsInfo')
PTs.orh <- aperm(array(unlist(info),dim=c(length(info[[1]]),2,3)),
                 c(1,3,2)
                )
```
Now, compare against ORh
========================

```{r, echo=FALSE}
par(mfrow=c(1,2))
info <- attr(nb.res,'itsInfo')
PTs.nb <- aperm(array(unlist(info),dim=c(length(info[[1]]),2,3)),
                 c(1,3,2)
                )
PRcurve(PTs.nb[,,1],PTs.nb[,,2],
        main='PR curve',lty=1,xlim=c(0,1),ylim=c(0,1),
        avg='vertical')
PRcurve(PTs.orh[,,1],PTs.orh[,,2],
        add=T,lty=1,col='grey',
        avg='vertical')        
legend('topright',c('NaiveBayes','ORh'),
       lty=1,col=c('black','grey'))
CRchart(PTs.nb[,,1],PTs.nb[,,2],
        main='Cumulative Recall curve',lty=1,xlim=c(0,1),ylim=c(0,1),
        avg='vertical')
CRchart(PTs.orh[,,1],PTs.orh[,,2],
        add=T,lty=1,col='grey',
        avg='vertical')        
legend('bottomright',c('NaiveBayes','ORh'),
       lty=1,col=c('black','grey'))
```

Why is it worse?
=================

Why is it worse?
================

-  Class imbalance?
-  Try to apply SMOTE

```{r, echo=FALSE}
nb.s <- function(train,test) {
  require(e1071,quietly=T)
  sup <- which(train$Insp != 'unkn')
  data <- train[sup,c('ID','Prod','Uprice','Insp')]
  data$Insp <- factor(data$Insp,levels=c('ok','fraud'))
  newData <- SMOTE(Insp ~ .,data,perc.over=700)
  model <- naiveBayes(Insp ~ .,newData)
  preds <- predict(model,test[,c('ID','Prod','Uprice','Insp')],type='raw')
  return(list(rankOrder=order(preds[,'fraud'],decreasing=T),
              rankScore=preds[,'fraud'])
         )
}


ho.nbs <- function(form, train, test, ...) {
  res <- nb.s(train,test)
  structure(evalOutlierRanking(test,res$rankOrder,...),
            itInfo=list(preds=res$rankScore,
                        trues=ifelse(test$Insp=='fraud',1,0)
                       )
           )
}
nbs.res <- holdOut(learner('ho.nbs',
                          pars=list(Threshold=0.1,
                                    statsProds=globalStats)),
                  dataset(Insp ~ .,sales),
                  hldSettings(3,0.3,1234,T),
                  itsInfo=TRUE
                  )
```


Results with SMOTE
==================
```{r}
summary(nbs.res)
```

Comparison plot
===============
```{r, echo=FALSE}
par(mfrow=c(1,2))
info <- attr(nbs.res,'itsInfo')
PTs.nbs <- aperm(array(unlist(info),dim=c(length(info[[1]]),2,3)),
                 c(1,3,2)
                )
PRcurve(PTs.nb[,,1],PTs.nb[,,2],
        main='PR curve',lty=1,xlim=c(0,1),ylim=c(0,1),
        avg='vertical')
PRcurve(PTs.nbs[,,1],PTs.nbs[,,2],
        add=T,lty=2,
        avg='vertical')
PRcurve(PTs.orh[,,1],PTs.orh[,,2],
        add=T,lty=1,col='grey',
        avg='vertical')        
legend('topright',c('NaiveBayes','smoteNaiveBayes','ORh'),
       lty=c(1,2,1),col=c('black','black','grey'))
CRchart(PTs.nb[,,1],PTs.nb[,,2],
        main='Cumulative Recall curve',lty=1,xlim=c(0,1),ylim=c(0,1),
        avg='vertical')
CRchart(PTs.nbs[,,1],PTs.nbs[,,2],
        add=T,lty=2,
        avg='vertical')
CRchart(PTs.orh[,,1],PTs.orh[,,2],
        add=T,lty=1,col='grey',
        avg='vertical')        
legend('bottomright',c('NaiveBayes','smoteNaiveBayes','ORh'),
       lty=c(1,2,1),col=c('black','black','grey'))
```
